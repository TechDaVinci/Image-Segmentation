{"cells":[{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["! pip install torch_optimizer\n","! pip install codecarbon\n","! pip install git+https://github.com/sovrasov/flops-counter.pytorch.git\n","! pip install skorch\n","! pip install gdown\n","from IPython.display import clear_output\n","clear_output()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32058,"status":"ok","timestamp":1690949725008,"user":{"displayName":"Mohammad Yusuf","userId":"07629047323356154624"},"user_tz":-330},"id":"SuWjP3SCMOyg","outputId":"e46229a9-2367-44f3-bc63-365f6774ff85"},"outputs":[],"source":["from IPython.display import clear_output\n","import os.path \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.ops\n","from torch.autograd import Variable, Function\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pickle\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","import torch_optimizer as optim\n","from torch.optim import Adam\n","from codecarbon.emissions_tracker import EmissionsTracker\n","import os\n","import shutil\n","from sklearn.metrics import accuracy_score, cohen_kappa_score, jaccard_score, precision_score, recall_score, f1_score, classification_report\n","from ptflops import get_model_complexity_info\n","import pandas as pd\n","from PIL import Image\n","import importlib\n","import torchvision\n","import torch.utils.data\n","import math\n","from torch.nn.parameter import Parameter\n","from torch.nn.functional import pad\n","from torch.nn.modules import Module\n","from torch.nn import ConvTranspose2d\n","from torch.nn.modules.utils import _single, _pair, _triple\n","import math\n","import gdown\n","import time"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["url = \"https://drive.google.com/drive/folders/17rQ2ALkfZPNtgkGmzr0tYVKYCPjPc5X7?usp=sharing\"\n","if not os.path.exists (\"./datasets\"):\n","    gdown.download_folder (url, quiet=False, use_cookies=False)\n","if not os.path.exists (\"./model\"):\n","     os.mkdir(\"model\")\n","if not os.path.exists (\"./output\"):\n","     os.mkdir(\"output\")\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"WP-mLOIPMt5P"},"source":["Convolutions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-LBiAUClMs8H"},"outputs":[],"source":["#conv2d\n","def conv2d(in_channels, out_channels, kernel_size, padding, bias=False):\n","    return nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, bias=bias)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T2Z9anEyMnw0"},"outputs":[],"source":["#Spacially separable conv\n","class SpatialSeparableConv2d(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, padding=0, bias=False):\n","        super(SpatialSeparableConv2d, self).__init__()\n","        assert isinstance(kernel_size, int)\n","        self.conv1 = nn.Conv2d(in_channels, in_channels, (kernel_size, 1), padding=(padding, 0), groups=in_channels, bias=bias)\n","        self.conv2 = nn.Conv2d(in_channels, out_channels, (1, kernel_size), padding=(0, padding), bias=bias)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVLWf76RM4yQ"},"outputs":[],"source":["#gaussian dynamic convolution\n","class HalfNormal(object):\n","    def __init__(self, scale, seed, device):\n","        self.scale = scale\n","        self.device = device\n","        torch.manual_seed(seed)\n","    def sample(self, sample_shape=torch.Size()):\n","        result = torch.zeros(sample_shape).to(self.device)\n","        result = result.normal_(mean=0, std=self.scale).abs()\n","        return result\n","class GFDConv(nn.Module):\n","    def __init__(self, in_features,out_features, bias=False, scale=0.1, device='cpu', seed=307, fix_w=0, fix_h=0):\n","        super(GFDConv, self).__init__()\n","        self.conv = nn.Conv2d(9 * in_features, out_features, 1, bias=bias)\n","        self.dis = HalfNormal(scale, seed, device)\n","        self.size = None\n","        self.device = device\n","        self.direction_basis = torch.tensor([[-1, 1, -1, 1, -1, 1, 0, 0],\n","                                             [-1, -1, 1, 1, 0, 0, -1, 1]]).float().view(-1).to(self.device)\n","        if fix_w != 0 and fix_h != 0:\n","            yy = torch.linspace(0, fix_h - 1, steps=fix_h).unsqueeze(1).repeat(1, fix_w).unsqueeze(-1).to(self.device)\n","            xx = torch.linspace(0, fix_w - 1, steps=fix_w).unsqueeze(0).repeat(fix_h, 1).unsqueeze(-1).to(self.device)\n","            self.base_coor = torch.cat([xx.repeat(1, 1, 8), yy.repeat(1, 1, 8)], dim=-1).to(self.device)\n","            self.size = torch.tensor([fix_w] * 8 + [fix_h] * 8).float().to(self.device)\n","    def forward(self, feat):\n","        sample_coor = self.sample_process(feat.size(2), feat.size(3))\n","        sample_coor_x = sample_coor[:, :, :8]\n","        sample_coor_y = sample_coor[:, :, 8:]\n","        feat = F.pad(feat, [1, 1, 1, 1]).to(sample_coor.device)\n","        offset_feat = feat[:, :, sample_coor_y, sample_coor_x]\n","        offset_feat = F.pad(offset_feat.permute(0, 4, 1, 2, 3).contiguous()\n","                            .view(offset_feat.size(0), -1, offset_feat.size(2), offset_feat.size(3)), [1, 1, 1, 1])\n","        feat = torch.cat([feat, offset_feat], dim=1)\n","        feat = self.conv.to(feat.device)(feat)[:, :, 1:-1, 1:-1]\n","        return feat\n","    def sample_process(self, h, w):\n","        if self.size is None:\n","            yy = torch.linspace(0, h - 1, steps=h).unsqueeze(1).repeat(1, w).unsqueeze(-1).to(self.device)\n","            xx = torch.linspace(0, w - 1, steps=w).unsqueeze(0).repeat(h, 1).unsqueeze(-1).to(self.device)\n","            base_coor = torch.cat([xx.repeat(1, 1, 8), yy.repeat(1, 1, 8)], dim=-1).to(self.device)\n","            size = torch.tensor([w] * 8 + [h] * 8).float().to(self.device)\n","        else:\n","            size = self.size\n","            base_coor = self.base_coor\n","        sample_ = self.dis.sample(torch.Size([h, w, 16]))\n","        offset = sample_ * self.direction_basis * size\n","        sample_coor = base_coor + offset\n","        sample_coor[:, :, :8] = torch.clamp(sample_coor[:, :, :8], min=0, max=w - 1)\n","        sample_coor[:, :, 8:] = torch.clamp(sample_coor[:, :, 8:], min=0, max=h - 1)\n","        return (sample_coor + 1).long()\n","def gaussian_dynamic_conv(in_channels, out_channels, kernel_size, padding, bias=False):\n","    fix_w = 0\n","    fix_h = 0\n","    seed = 307\n","    scale = 2\n","    return GFDConv(in_channels, out_channels, bias, scale, 'cuda', seed, fix_w, fix_h)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QQ33z-PcNADZ"},"outputs":[],"source":["#deformable convolution\n","class DeformableConv2d(nn.Module):\n","    def __init__(self,in_channels,out_channels,kernel_size=3,stride=1,padding=1,dilation=1,bias=False):\n","        super(DeformableConv2d, self).__init__()\n","        assert type(kernel_size) == tuple or type(kernel_size) == int\n","        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n","        self.stride = stride if type(stride) == tuple else (stride, stride)\n","        self.padding = padding\n","        self.dilation = dilation\n","        self.offset_conv = nn.Conv2d(in_channels,2 * kernel_size[0] * kernel_size[1],kernel_size=kernel_size,stride=stride,padding=self.padding,dilation=self.dilation,bias=True)\n","        nn.init.constant_(self.offset_conv.weight, 0.)\n","        nn.init.constant_(self.offset_conv.bias, 0.)\n","        self.modulator_conv = nn.Conv2d(in_channels,1 * kernel_size[0] * kernel_size[1],kernel_size=kernel_size,stride=stride,padding=self.padding,dilation=self.dilation,bias=True)\n","        nn.init.constant_(self.modulator_conv.weight, 0.)\n","        nn.init.constant_(self.modulator_conv.bias, 0.)\n","        self.regular_conv = nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=kernel_size,stride=stride,padding=self.padding,dilation=self.dilation,bias=bias)\n","    def forward(self, x):\n","        offset = self.offset_conv(x)\n","        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n","        x = torchvision.ops.deform_conv2d(input=x,offset=offset,weight=self.regular_conv.weight,bias=self.regular_conv.bias,padding=self.padding,mask=modulator,stride=self.stride,dilation=self.dilation)\n","        return x\n","def deformable_conv(in_channels, out_channels, kernel_size, padding, bias=False):\n","    stride = 1\n","    dilation = 1\n","    return DeformableConv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, bias)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWbOrilXNCgA"},"outputs":[],"source":["#Adaptive deformable convolution\n","class DeformConv2d(nn.Module):\n","    def __init__(self, inc, outc, kernel_size=3, padding=1, stride=1, bias=None, modulation=False):\n","        super(DeformConv2d, self).__init__()\n","        self.kernel_size = kernel_size\n","        self.padding = padding\n","        self.stride = stride\n","        self.zero_padding = nn.ZeroPad2d(padding)\n","        self.conv = nn.Conv2d(inc, outc, kernel_size=kernel_size, stride=kernel_size, bias=bias)\n","        self.conv_weight_m = torch.ones([outc,inc,kernel_size,kernel_size], requires_grad=False).cuda()\n","        self.p_conv = nn.Conv2d(inc, 2*kernel_size*kernel_size, kernel_size=3, padding=1, stride=stride)\n","        nn.init.constant_(self.p_conv.weight, 0)\n","        self.p_conv.register_backward_hook(self._set_lr)\n","        self.modulation = modulation\n","        if modulation:\n","            self.m_conv = nn.Conv2d(inc, kernel_size*kernel_size, kernel_size=3, padding=1, stride=stride)\n","            nn.init.constant_(self.m_conv.weight, 0.5)\n","            self.m_conv.register_backward_hook(self._set_lr)\n","    @staticmethod\n","    def _set_lr(module, grad_input, grad_output):\n","        grad_input = (grad_input[i] * 0.1 for i in range(len(grad_input)))\n","        grad_output = (grad_output[i] * 0.1 for i in range(len(grad_output)))\n","    def forward(self, x):\n","        offset = self.p_conv(x)\n","        if self.modulation:\n","            m = torch.sigmoid(self.m_conv(x))\n","        dtype = offset.data.type()\n","        ks = self.kernel_size\n","        N = offset.size(1) // 2\n","        if self.padding:\n","            x = self.zero_padding(x)\n","        p = self._get_p(offset, dtype)\n","        p = p.contiguous().permute(0, 2, 3, 1)\n","        q_lt = Variable(p.data, requires_grad=False).floor()\n","        q_rb = q_lt + 1\n","        q_lt = torch.cat([torch.clamp(q_lt[..., :N], 0, x.size(2)-1), torch.clamp(q_lt[..., N:], 0, x.size(3)-1)], dim=-1).long()\n","        q_rb = torch.cat([torch.clamp(q_rb[..., :N], 0, x.size(2)-1), torch.clamp(q_rb[..., N:], 0, x.size(3)-1)], dim=-1).long()\n","        q_lb = torch.cat([q_lt[..., :N], q_rb[..., N:]], -1)\n","        q_rt = torch.cat([q_rb[..., :N], q_lt[..., N:]], -1)\n","        mask = torch.cat([p[..., :N].lt(self.padding)+p[..., :N].gt(x.size(2)-1-self.padding),\n","                          p[..., N:].lt(self.padding)+p[..., N:].gt(x.size(3)-1-self.padding)], dim=-1).type_as(p)\n","        mask = mask.detach()\n","        floor_p = p - (p - torch.floor(p))\n","        p = p*(1-mask) + floor_p*mask\n","        p = torch.cat([torch.clamp(p[..., :N], 0, x.size(2)-1), torch.clamp(p[..., N:], 0, x.size(3)-1)], dim=-1)\n","        g_lt = (1 + (q_lt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_lt[..., N:].type_as(p) - p[..., N:]))\n","        g_rb = (1 - (q_rb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_rb[..., N:].type_as(p) - p[..., N:]))\n","        g_lb = (1 + (q_lb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_lb[..., N:].type_as(p) - p[..., N:]))\n","        g_rt = (1 - (q_rt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_rt[..., N:].type_as(p) - p[..., N:]))\n","        x_q_lt = self._get_x_q(x, q_lt, N)\n","        x_q_rb = self._get_x_q(x, q_rb, N)\n","        x_q_lb = self._get_x_q(x, q_lb, N)\n","        x_q_rt = self._get_x_q(x, q_rt, N)\n","        x_offset = g_lt.unsqueeze(dim=1) * x_q_lt + \\\n","                   g_rb.unsqueeze(dim=1) * x_q_rb + \\\n","                   g_lb.unsqueeze(dim=1) * x_q_lb + \\\n","                   g_rt.unsqueeze(dim=1) * x_q_rt\n","        if self.modulation:\n","            m = m.contiguous().permute(0, 2, 3, 1)\n","            m = m.unsqueeze(dim=1)\n","            m = torch.cat([m for _ in range(x_offset.size(1))], dim=1)\n","            x_offset *= m\n","        x_offset = self._reshape_x_offset(x_offset, ks)\n","        out = self.conv(x_offset)\n","        return out\n","    def _get_p_n(self, N, dtype):\n","        p_n_x, p_n_y = torch.meshgrid(\n","            torch.arange(-(self.kernel_size-1)//2, (self.kernel_size-1)//2+1),\n","            torch.arange(-(self.kernel_size-1)//2, (self.kernel_size-1)//2+1))\n","        p_n = torch.cat([torch.flatten(p_n_x), torch.flatten(p_n_y)], 0)\n","        p_n = p_n.view(1, 2*N, 1, 1).type(dtype)\n","        return p_n\n","    def _get_p_0(self, h, w, N, dtype):\n","        p_0_x, p_0_y = torch.meshgrid(\n","            torch.arange(1, h*self.stride+1, self.stride),\n","            torch.arange(1, w*self.stride+1, self.stride))\n","        p_0_x = torch.flatten(p_0_x).view(1, 1, h, w).repeat(1, N, 1, 1)\n","        p_0_y = torch.flatten(p_0_y).view(1, 1, h, w).repeat(1, N, 1, 1)\n","        p_0 = torch.cat([p_0_x, p_0_y], 1).type(dtype)\n","        return p_0\n","    def _get_p(self, offset, dtype):\n","        N, h, w = offset.size(1)//2, offset.size(2), offset.size(3)\n","        p_n = self._get_p_n(N, dtype)\n","        p_0 = self._get_p_0(h, w, N, dtype)\n","        p = p_0 + p_n + offset\n","        return p\n","    def _get_x_q(self, x, q, N):\n","        b, h, w, _ = q.size()\n","        padded_w = x.size(3)\n","        c = x.size(1)\n","        x = x.contiguous().view(b, c, -1)\n","        index = q[..., :N]*padded_w + q[..., N:]\n","        index = index.contiguous().unsqueeze(dim=1).expand(-1, c, -1, -1, -1).contiguous().view(b, c, -1)\n","        x_offset = x.gather(dim=-1, index=index).contiguous().view(b, c, h, w, N)\n","        return x_offset\n","    @staticmethod\n","    def _reshape_x_offset(x_offset, ks):\n","        b, c, h, w, N = x_offset.size()\n","        x_offset = torch.cat([x_offset[..., s:s+ks].contiguous().view(b, c, h, w*ks) for s in range(0, N, ks)], dim=-1)\n","        x_offset = x_offset.contiguous().view(b, c, h*ks, w*ks)\n","        return x_offset\n","\n","def Adaptive_deformable_conv(in_channels, out_channels, kernel_size, padding, bias=False):\n","\tstride=1\n","\tmodulation=False\n","\tbias = None\n","\treturn DeformConv2d(in_channels,out_channels,kernel_size,padding,stride,bias,modulation)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKOmfSBjNRND"},"outputs":[],"source":["#Asymmetric convolution\n","class orgACBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n","        super(orgACBlock, self).__init__()\n","        c1 = int(out_channels*0.33)\n","        c2 = int(out_channels*0.33)\n","        c3 = out_channels - c1 - c2\n","        self.square_conv = nn.Conv2d(in_channels,c1 , (kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n","        self.ver_conv = nn.Conv2d(in_channels,c2 , (kernel_size, 1), stride=stride, padding=(padding, 0), dilation=dilation, groups=groups, bias=bias)\n","        self.hor_conv = nn.Conv2d(in_channels, c3, (1, kernel_size), stride=stride, padding=(0, padding), dilation=dilation, groups=groups, bias=bias)\n","    def forward(self, x):\n","        x1 = self.square_conv(x)\n","        x2 = self.ver_conv(x)\n","        x3 = self.hor_conv(x)\n","        x = torch.cat([x1,x2,x3], dim=1)\n","        return x\n","\n","class ACBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n","        super(ACBlock, self).__init__()\n","        c1 = int(out_channels*0.5)\n","        c2 = int(out_channels*0.33)\n","        c3 = out_channels - c1 - c2\n","        self.square_conv = nn.Conv2d(in_channels,c1 , (kernel_size, kernel_size), stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n","        self.ver_conv = nn.Conv2d(in_channels,c2 , (kernel_size, 1), stride=stride, padding=(padding, 0), dilation=dilation, groups=groups, bias=bias)\n","        self.hor_conv = nn.Conv2d(in_channels, c3, (1, kernel_size), stride=stride, padding=(0, padding), dilation=dilation, groups=groups, bias=bias)\n","    def forward(self, x):\n","        x1 = self.square_conv(x)\n","        x2 = self.ver_conv(x)\n","        x3 = self.hor_conv(x)\n","        x = torch.cat([x1,x2,x3], dim=1)\n","        return x\n","\n","\n","\n","class GD_AC(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n","        super(GD_AC, self).__init__()\n","        assert isinstance(kernel_size, int)\n","        c1 = int(out_channels*0.5)\n","        c2 = int(out_channels*0.33)\n","        c3 = out_channels - c1 - c2\n","        self.square_conv = gaussian_dynamic_conv(in_channels, c1, kernel_size, padding, bias=False)\n","        self.ver_conv = nn.Conv2d(in_channels, c2, (kernel_size, 1), stride=stride, padding=(padding, 0), dilation=dilation, groups=groups, bias=bias)\n","        self.hor_conv = nn.Conv2d(in_channels, c3, (1, kernel_size), stride=stride, padding=(0, padding), dilation=dilation, groups=groups, bias=bias)\n","\n","    def forward(self, x):\n","        x1 = self.square_conv(x)\n","        x2 = self.ver_conv(x)\n","        x3 = self.hor_conv(x)\n","        x = torch.cat([x1,x2,x3], dim=1)\n","        return x\n","\n","class D_AC(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n","        super(D_AC, self).__init__()\n","        assert isinstance(kernel_size, int)\n","        c1 = int(out_channels*0.5)\n","        c2 = int(out_channels*0.33)\n","        c3 = out_channels - c1 - c2\n","        self.square_conv = deformable_conv(in_channels, c1, kernel_size, padding, bias=False)\n","        self.ver_conv = nn.Conv2d(in_channels, c2, (kernel_size, 1), stride=stride, padding=(padding, 0), dilation=dilation, groups=groups, bias=bias)\n","        self.hor_conv = nn.Conv2d(in_channels, c3, (1, kernel_size), stride=stride, padding=(0, padding), dilation=dilation, groups=groups, bias=bias)\n","\n","    def forward(self, x):\n","        x1 = self.square_conv(x)\n","        x2 = self.ver_conv(x)\n","        x3 = self.hor_conv(x)\n","        x = torch.cat([x1,x2,x3], dim=1)\n","        return x\n","\n","class AD_AC(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n","        super(AD_AC, self).__init__()\n","        assert isinstance(kernel_size, int)\n","        c1 = int(out_channels*0.5)\n","        c2 = int(out_channels*0.33)\n","        c3 = out_channels - c1 - c2\n","        self.square_conv = Adaptive_deformable_conv(in_channels, c1, kernel_size, padding, bias=False)\n","        self.ver_conv = nn.Conv2d(in_channels, c2, (kernel_size, 1), stride=stride, padding=(padding, 0), dilation=dilation, groups=groups, bias=bias)\n","        self.hor_conv = nn.Conv2d(in_channels, c3, (1, kernel_size), stride=stride, padding=(0, padding), dilation=dilation, groups=groups, bias=bias)\n","\n","    def forward(self, x):\n","        x1 = self.square_conv(x)\n","        x2 = self.ver_conv(x)\n","        x3 = self.hor_conv(x)\n","        x = torch.cat([x1,x2,x3], dim=1)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conv_function = [conv2d, SpatialSeparableConv2d, gaussian_dynamic_conv, deformable_conv,Adaptive_deformable_conv,orgACBlock,ACBlock,GD_AC,D_AC,AD_AC]"]},{"cell_type":"markdown","metadata":{"id":"NwAiq-uNNWf8"},"source":["Unet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0vT7BuMnNVmp"},"outputs":[],"source":["class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None,index=0):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","\n","            conv_function[index](in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            conv_function[index](mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","    def forward(self, x):\n","        return self.double_conv(x)\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=True):\n","        super().__init__()\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","            self.conv = DoubleConv(in_channels, out_channels)\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","    def forward(self, x):\n","        return self.conv(x)\n","class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False,index = 0):\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","        self.index = index\n","        self.inc = (DoubleConv(n_channels, 64,index))\n","        self.down1 = (Down(64, 128))\n","        self.down2 = (Down(128, 256))\n","        self.down3 = (Down(256, 512))\n","        factor = 2 if bilinear else 1\n","        self.down4 = (Down(512, 1024 // factor))\n","        self.up1 = (Up(1024, 512 // factor, bilinear))\n","        self.up2 = (Up(512, 256 // factor, bilinear))\n","        self.up3 = (Up(256, 128 // factor, bilinear))\n","        self.up4 = (Up(128, 64, bilinear))\n","        self.outc = (OutConv(64, n_classes))\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        return logits\n","    def use_checkpointing(self):\n","        self.inc = torch.utils.checkpoint(self.inc)\n","        self.down1 = torch.utils.checkpoint(self.down1)\n","        self.down2 = torch.utils.checkpoint(self.down2)\n","        self.down3 = torch.utils.checkpoint(self.down3)\n","        self.down4 = torch.utils.checkpoint(self.down4)\n","        self.up1 = torch.utils.checkpoint(self.up1)\n","        self.up2 = torch.utils.checkpoint(self.up2)\n","        self.up3 = torch.utils.checkpoint(self.up3)\n","        self.up4 = torch.utils.checkpoint(self.up4)\n","        self.outc = torch.utils.checkpoint(self.outc)"]},{"cell_type":"markdown","metadata":{"id":"xkzbJmMVN97o"},"source":["Attention-Unet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9_rL_kL7NvFf"},"outputs":[],"source":["class conv_block(nn.Module):\n","    def __init__(self, in_ch, out_ch,index=0):\n","        super(conv_block, self).__init__()\n","\n","        self.conv = nn.Sequential(\n","            conv_function[index](in_ch, out_ch, kernel_size=3,  padding=1, bias=True),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","            conv_function[index](out_ch, out_ch, kernel_size=3, padding=1, bias=True),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True))\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        return x\n","\n","class up_conv(nn.Module):\n","    def __init__(self, in_ch, out_ch):\n","        super(up_conv, self).__init__()\n","        self.up = nn.Sequential(\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        x = self.up(x)\n","        return x\n","\n","class Attention_block(nn.Module):\n","    def __init__(self, F_g, F_l, F_int):\n","        super(Attention_block, self).__init__()\n","\n","        self.W_g = nn.Sequential(\n","            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n","            nn.BatchNorm2d(F_int)\n","        )\n","\n","        self.W_x = nn.Sequential(\n","            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n","            nn.BatchNorm2d(F_int)\n","        )\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n","            nn.BatchNorm2d(1),\n","            nn.Sigmoid()\n","        )\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, g, x):\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(x)\n","        psi = self.relu(g1 + x1)\n","        psi = self.psi(psi)\n","        out = x * psi\n","        return out\n","class AttenUNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False,index = 0):\n","        super(AttenUNet, self).__init__()\n","        img_ch=n_channels\n","        output_ch=n_classes\n","        self.index=index\n","        n1=64\n","        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n","        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.Conv1 = conv_block(img_ch, filters[0],index)\n","        self.Conv2 = conv_block(filters[0], filters[1],index)\n","        self.Conv3 = conv_block(filters[1], filters[2],index)\n","        self.Conv4 = conv_block(filters[2], filters[3],index)\n","        self.Conv5 = conv_block(filters[3], filters[4],index)\n","        self.Up5 = up_conv(filters[4], filters[3])\n","        self.Att5 = Attention_block(F_g=filters[3], F_l=filters[3], F_int=filters[2])\n","        self.Up_conv5 = conv_block(filters[4], filters[3],index)\n","        self.Up4 = up_conv(filters[3], filters[2])\n","        self.Att4 = Attention_block(F_g=filters[2], F_l=filters[2], F_int=filters[1])\n","        self.Up_conv4 = conv_block(filters[3], filters[2],index)\n","        self.Up3 = up_conv(filters[2], filters[1])\n","        self.Att3 = Attention_block(F_g=filters[1], F_l=filters[1], F_int=filters[0])\n","        self.Up_conv3 = conv_block(filters[2], filters[1],index)\n","        self.Up2 = up_conv(filters[1], filters[0])\n","        self.Att2 = Attention_block(F_g=filters[0], F_l=filters[0], F_int=32)\n","        self.Up_conv2 = conv_block(filters[1], filters[0],index)\n","        self.Conv = nn.Conv2d(filters[0], output_ch, kernel_size=1, stride=1, padding=0)\n","    def forward(self, x):\n","        e1 = self.Conv1(x)\n","        e2 = self.Maxpool1(e1)\n","        e2 = self.Conv2(e2)\n","        e3 = self.Maxpool2(e2)\n","        e3 = self.Conv3(e3)\n","        e4 = self.Maxpool3(e3)\n","        e4 = self.Conv4(e4)\n","        e5 = self.Maxpool4(e4)\n","        e5 = self.Conv5(e5)\n","        d5 = self.Up5(e5)\n","        x4 = self.Att5(g=d5, x=e4)\n","        d5 = torch.cat((x4, d5), dim=1)\n","        d5 = self.Up_conv5(d5)\n","        d4 = self.Up4(d5)\n","        x3 = self.Att4(g=d4, x=e3)\n","        d4 = torch.cat((x3, d4), dim=1)\n","        d4 = self.Up_conv4(d4)\n","        d3 = self.Up3(d4)\n","        x2 = self.Att3(g=d3, x=e2)\n","        d3 = torch.cat((x2, d3), dim=1)\n","        d3 = self.Up_conv3(d3)\n","        d2 = self.Up2(d3)\n","        x1 = self.Att2(g=d2, x=e1)\n","        d2 = torch.cat((x1, d2), dim=1)\n","        d2 = self.Up_conv2(d2)\n","        out = self.Conv(d2)\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"qUQLTcKaOQ84"},"source":["UNet++"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZ7G3rpaOGLw"},"outputs":[],"source":["class conv_block_nested(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None,index=0):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.conv = nn.Sequential(\n","\n","            conv_function[index](in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            conv_function[index](mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","    def forward(self, inputs):\n","        return self.conv(inputs)\n","\n","class UNetplusplus(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False,index = 0):\n","        super(UNetplusplus, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","        self.index = index\n","        n1 = 64\n","        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.Up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        self.conv0_0 = conv_block_nested(n_channels, filters[0], filters[0],index)\n","        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1],index)\n","        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2],index)\n","        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3],index)\n","        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4],index)\n","        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0],index)\n","        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1],index)\n","        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2],index)\n","        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3],index)\n","        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0],index)\n","        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1],index)\n","        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2],index)\n","        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0],index)\n","        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1],index)\n","        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0],index)\n","        self.final = nn.Conv2d(filters[0], n_classes, kernel_size=1)\n","    def forward(self, x):\n","        x0_0 = self.conv0_0(x)\n","        x1_0 = self.conv1_0(self.pool(x0_0))\n","        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up(x1_0)], 1))\n","        x2_0 = self.conv2_0(self.pool(x1_0))\n","        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up(x2_0)], 1))\n","        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up(x1_1)], 1))\n","        x3_0 = self.conv3_0(self.pool(x2_0))\n","        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up(x3_0)], 1))\n","        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up(x2_1)], 1))\n","        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up(x1_2)], 1))\n","        x4_0 = self.conv4_0(self.pool(x3_0))\n","        x3_1 = self.conv3_1(torch.cat([x3_0, self.Up(x4_0)], 1))\n","        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.Up(x3_1)], 1))\n","        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.Up(x2_2)], 1))\n","        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.Up(x1_3)], 1))\n","        output = self.final(x0_4)\n","        return output\n","    def use_checkpointing(self):\n","        self.conv0_0 = torch.utils.checkpoint(self.conv0_0)\n","        self.conv1_0 = torch.utils.checkpoint(self.conv1_0)\n","        self.conv0_1 = torch.utils.checkpoint(self.conv0_1)\n","        self.conv2_0 = torch.utils.checkpoint(self.conv2_0)\n","        self.conv1_1 = torch.utils.checkpoint(self.conv1_1)\n","        self.conv0_2 = torch.utils.checkpoint(self.conv0_2)\n","        self.conv3_0 = torch.utils.checkpoint(self.conv3_0)\n","        self.conv2_1 = torch.utils.checkpoint(self.conv2_1)\n","        self.conv1_2 = torch.utils.checkpoint(self.conv1_2)\n","        self.conv0_3 = torch.utils.checkpoint(self.conv0_3)\n","        self.conv4_0 = torch.utils.checkpoint(self.conv4_0)\n","        self.conv3_1 = torch.utils.checkpoint(self.conv3_1)\n","        self.conv2_2 = torch.utils.checkpoint(self.conv2_2)\n","        self.conv1_3 = torch.utils.checkpoint(self.conv1_3)\n","        self.conv0_4 = torch.utils.checkpoint(self.conv0_4)\n","        self.final = torch.utils.checkpoint(self.final)"]},{"cell_type":"markdown","metadata":{},"source":["SegCaps"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#nn\n","class _ConvNd(Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride,\n","                 padding, dilation, transposed, output_padding, groups, bias):\n","        super(_ConvNd, self).__init__()\n","        if in_channels % groups != 0:\n","            raise ValueError('in_channels must be divisible by groups')\n","        if out_channels % groups != 0:\n","            raise ValueError('out_channels must be divisible by groups')\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        self.dilation = dilation\n","        self.transposed = transposed\n","        self.output_padding = output_padding\n","        self.groups = groups\n","        if transposed:\n","            self.weight = Parameter(torch.Tensor(\n","                in_channels, out_channels // groups, *kernel_size))\n","        else:\n","            self.weight = Parameter(torch.Tensor(\n","                out_channels, in_channels // groups, *kernel_size))\n","        if bias:\n","            self.bias = Parameter(torch.Tensor(out_channels))\n","        else:\n","            self.register_parameter('bias', None)\n","        self.reset_parameters()\n","    def reset_parameters(self):\n","        n = self.in_channels\n","        for k in self.kernel_size:\n","            n *= k\n","        stdv = 1. / math.sqrt(n)\n","        self.weight.data.uniform_(-stdv, stdv)\n","        if self.bias is not None:\n","            self.bias.data.uniform_(-stdv, stdv)\n","    def extra_repr(self):\n","        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n","             ', stride={stride}')\n","        if self.padding != (0,) * len(self.padding):\n","            s += ', padding={padding}'\n","        if self.dilation != (1,) * len(self.dilation):\n","            s += ', dilation={dilation}'\n","        if self.output_padding != (0,) * len(self.output_padding):\n","            s += ', output_padding={output_padding}'\n","        if self.groups != 1:\n","            s += ', groups={groups}'\n","        if self.bias is None:\n","            s += ', bias=False'\n","        return s.format(**self.__dict__)\n","class Conv2d(_ConvNd):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n","                 padding=0, dilation=1, groups=1, bias=False):\n","        kernel_size = _pair(kernel_size)\n","        stride = _pair(stride)\n","        padding = _pair(padding)\n","        dilation = _pair(dilation)\n","        super(Conv2d, self).__init__(\n","            in_channels, out_channels, kernel_size, stride, padding, dilation,\n","            False, _pair(0), groups, bias)\n","    def forward(self, input):\n","        return conv2d_same(input, self.weight, self.bias, self.stride,\n","                           self.dilation, self.groups)\n","class ConvTranspose2d(nn.ConvTranspose2d):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n","                 padding=0, output_padding=0, groups=1, bias=False, dilation=1):\n","        super(ConvTranspose2d, self).__init__(\n","            in_channels, out_channels, kernel_size, stride, padding, output_padding, groups, bias, dilation)\n","    def forward(self, input):\n","        input_size = input.size(2)\n","        output_size = input_size*self.stride[0]\n","        pad_l, pad_r = get_same(input_size,self.kernel_size[0],self.stride[0],dilation=1)\n","        self.padding=max(pad_l,pad_r)\n","        input_size=(input_size-1)*self.stride[0]+self.kernel_size[0]-2*self.padding\n","        output_padding=output_size-input_size\n","        return F.conv_transpose2d(\n","            input, self.weight, self.bias, self.stride, self.padding,\n","            output_padding, self.groups, self.dilation)\n","def conv2d_same(input, weight, bias=None, stride=[1, 1], dilation=(1, 1), groups=1):\n","    input_rows = input.size(2)\n","    filter_rows = weight.size(2)\n","    out_rows = (input_rows + stride[0] - 1) // stride[0]\n","    padding_rows = max(0, (out_rows - 1) * stride[0] +\n","                       (filter_rows - 1) * dilation[0] + 1 - input_rows)\n","    rows_odd = (padding_rows % 2 != 0)\n","    padding_cols = max(0, (out_rows - 1) * stride[0] +\n","                       (filter_rows - 1) * dilation[0] + 1 - input_rows)\n","    cols_odd = (padding_rows % 2 != 0)\n","    if rows_odd or cols_odd:\n","        input = pad(input, [0, int(cols_odd), 0, int(rows_odd)])\n","    return F.conv2d(input, weight, bias, stride,\n","                    padding=(padding_rows // 2, padding_cols // 2),\n","                    dilation=dilation, groups=groups)\n","def max_pool2d_same(input, kernel_size, stride=1, dilation=1, ceil_mode=False, return_indices=False):\n","    input_rows = input.size(2)\n","    out_rows = (input_rows + stride - 1) // stride\n","    padding_rows = max(0, (out_rows - 1) * stride +\n","                       (kernel_size - 1) * dilation + 1 - input_rows)\n","    rows_odd = (padding_rows % 2 != 0)\n","    cols_odd = (padding_rows % 2 != 0)\n","    if rows_odd or cols_odd:\n","        input = pad(input, [0, int(cols_odd), 0, int(rows_odd)])\n","    return F.max_pool2d(input, kernel_size=kernel_size, stride=stride, padding=padding_rows // 2, dilation=dilation,\n","                        ceil_mode=ceil_mode, return_indices=return_indices)\n","def get_same(size, kernel, stride, dilation):\n","    out_size = (size + stride - 1) // stride\n","    padding = max(0, (out_size - 1) * stride +\n","                  (kernel - 1) * dilation + 1 - size)\n","    size_odd = (padding % 2 != 0)\n","    pad_l = padding // 2\n","    pad_r = padding // 2\n","    if size_odd:\n","        pad_l += 1\n","    return pad_l, pad_r\n","#capsule layer\n","class CapsuleLayer(nn.Module):\n","    def __init__(self, t_0,z_0, op, k, s, t_1, z_1, routing):\n","        super().__init__()\n","        self.t_1 = t_1\n","        self.z_1 = z_1\n","        self.op = op\n","        self.k = k\n","        self.s = s\n","        self.routing = routing\n","        self.convs = nn.ModuleList()\n","        self.t_0=t_0\n","        for _ in range(t_0):\n","            if self.op=='conv':\n","                self.convs.append(nn.Conv2d(z_0, self.t_1*self.z_1, self.k, self.s,padding=2,bias=False))\n","            else:\n","                self.convs.append(nn.ConvTranspose2d(z_0, self.t_1 * self.z_1, self.k, self.s,padding=2,output_padding=1))\n","    def forward(self, u): \n","        if u.shape[1]!=self.t_0:\n","            raise ValueError(\"Wrong type of operation for capsule\")\n","        op = self.op\n","        k = self.k\n","        s = self.s\n","        t_1 = self.t_1\n","        z_1 = self.z_1\n","        routing = self.routing\n","        N = u.shape[0]\n","        H_1=u.shape[3]\n","        W_1=u.shape[4]\n","        t_0 = self.t_0\n","        u_t_list = [u_t.squeeze(1) for u_t in u.split(1, 1)] \n","        u_hat_t_list = []\n","        for i, u_t in zip(range(self.t_0), u_t_list):  \n","            if op == \"conv\":\n","                u_hat_t = self.convs[i](u_t)  \n","            elif op == \"deconv\":\n","                u_hat_t = self.convs[i](u_t) \n","            else:\n","                raise ValueError(\"Wrong type of operation for capsule\")\n","            H_1 = u_hat_t.shape[2]\n","            W_1 = u_hat_t.shape[3]\n","            u_hat_t = u_hat_t.reshape(N, t_1,z_1,H_1, W_1).transpose_(1,3).transpose_(2,4)\n","            u_hat_t_list.append(u_hat_t)   \n","        v=self.update_routing(u_hat_t_list,k,N,H_1,W_1,t_0,t_1,routing)\n","        return v\n","    def update_routing(self,u_hat_t_list, k, N, H_1, W_1, t_0, t_1, routing):\n","        one_kernel = torch.ones(1, t_1, k, k).cuda()\n","        b = torch.zeros(N, H_1, W_1, t_0, t_1).cuda()  \n","        b_t_list = [b_t.squeeze(3) for b_t in b.split(1, 3)]\n","        u_hat_t_list_sg = []\n","        for u_hat_t in u_hat_t_list:\n","            u_hat_t_sg=u_hat_t.detach()\n","            u_hat_t_list_sg.append(u_hat_t_sg)\n","        for d in range(routing):\n","            if d < routing - 1:\n","                u_hat_t_list_ = u_hat_t_list_sg\n","            else:\n","                u_hat_t_list_ = u_hat_t_list\n","            r_t_mul_u_hat_t_list = []\n","            for b_t, u_hat_t in zip(b_t_list, u_hat_t_list_):\n","                b_t.transpose_(1, 3).transpose_(2, 3)  \n","                b_t_max = torch.nn.functional.max_pool2d(b_t,k,1,padding=2)\n","                b_t_max = b_t_max.max(1, True)[0]\n","                c_t = torch.exp(b_t - b_t_max)\n","                sum_c_t = conv2d_same(c_t, one_kernel, stride=(1, 1)) \n","                r_t = c_t / sum_c_t  \n","                r_t = r_t.transpose(1, 3).transpose(1, 2)  \n","                r_t = r_t.unsqueeze(4)  \n","                r_t_mul_u_hat_t_list.append(r_t * u_hat_t)  \n","            p = sum(r_t_mul_u_hat_t_list) \n","            v = squash(p)\n","            if d < routing - 1:\n","                b_t_list_ = []\n","                for b_t, u_hat_t in zip(b_t_list, u_hat_t_list_):\n","                    b_t.transpose_(1,3).transpose_(2,1)\n","                    b_t_list_.append(b_t + (u_hat_t * v).sum(4))\n","        v.transpose_(1, 3).transpose_(2, 4)\n","        return v\n","    def squash(self, p):\n","        p_norm_sq = (p * p).sum(-1, True)\n","        p_norm = (p_norm_sq + 1e-9).sqrt()\n","        v = p_norm_sq / (1. + p_norm_sq) * p / p_norm\n","        return v\n","def update_routing(u_hat_t_list,k,N,H_1,W_1,t_0,t_1,routing):\n","    one_kernel = torch.ones(1, t_1, k, k).cuda()\n","    b = torch.zeros(N, H_1, W_1, t_0, t_1 ).cuda()\n","    b_t_list = [b_t.squeeze(3) for b_t in b.split(1, 3)]\n","    u_hat_t_list_sg = []\n","    for u_hat_t in u_hat_t_list:\n","        u_hat_t_sg = u_hat_t.clone()\n","        u_hat_t_sg.detach_()\n","        u_hat_t_list_sg.append(u_hat_t_sg)\n","    for d in range(routing):\n","        if d < routing - 1:\n","            u_hat_t_list_ = u_hat_t_list_sg\n","        else:\n","            u_hat_t_list_ = u_hat_t_list\n","        r_t_mul_u_hat_t_list = []\n","        for b_t, u_hat_t in zip(b_t_list, u_hat_t_list_):\n","            b_t.transpose_(1, 3).transpose_(2, 3)\n","            torch.nn.functional.max_pool2d(b_t,k,)\n","            b_t_max = max_pool2d_same(b_t, k, 1)\n","            b_t_max = b_t_max.max(1, True)[0]\n","            c_t = torch.exp(b_t - b_t_max)\n","            sum_c_t = conv2d_same(c_t, one_kernel, stride=(1, 1)) \n","            r_t = c_t / sum_c_t \n","            r_t = r_t.transpose(1, 3).transpose(1, 2)  \n","            r_t = r_t.unsqueeze(4)  \n","            r_t_mul_u_hat_t_list.append(r_t * u_hat_t) \n","        p = sum(r_t_mul_u_hat_t_list)  \n","        v = squash(p)\n","        if d < routing - 1:\n","            b_t_list_ = []\n","            for b_t, u_hat_t in zip(b_t_list, u_hat_t_list_):\n","                b_t = b_t.transpose(1, 3).transpose(1, 2)\n","                b_t_list_.append(b_t + (u_hat_t * v).sum(4))\n","            b_t_list = b_t_list_\n","        v.transpose_(1,3).transpose_(2,4)\n","    return v\n","def squash( p):\n","    p_norm_sq = (p * p).sum(-1, True)\n","    p_norm = (p_norm_sq + 1e-9).sqrt()\n","    v = p_norm_sq / (1. + p_norm_sq) * p / p_norm\n","    return v\n","def test():\n","    m=CapsuleLayer(1, 16, \"conv\", k=5, s=1, t_1=2, z_1=16, routing=1)\n","    m=m.cuda()\n","    b=input('s')\n","    a=torch.randn(10, 1, 16, int(b), int(b))\n","    a=a.cuda()\n","    optimizer = optim.Adam(m.parameters(), lr=1)\n","    for k,v in m.named_parameters():\n","        print(k)\n","    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20],\n","                                               gamma=0.1)\n","    b=m(a)\n","    c=b.mean()\n","    for k in m.parameters():\n","        print(k)\n","    print(b.shape)\n","    print(c)\n","    c.backward()\n","    optimizer.step()\n","    b=m(a)\n","    c=b.mean()\n","    print(c)\n","    print(a.grad)\n","    print(b.shape)\n","def test1():\n","    import os\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","    a = []\n","\n","    b = torch.ones([1, 10, 10, 2, 3]).cuda()\n","    print(b)\n","    a.append(b)\n","    c = update_routing(a, 2, 1, 10, 10, 1, 2,3)\n","    print(c.cpu().numpy())\n","\n","#capsulener\n","class SegCaps(nn.Module):\n","    def __init__(self,n_channels, n_classes, bilinear=False,index = 0):\n","        super().__init__()\n","        self.conv_1 = nn.Sequential(\n","            conv_function[index](3, 16, 5, padding=2,bias=False),\n","        )\n","        self.step_1 = nn.Sequential(  # 1/2\n","            CapsuleLayer(1, 16, \"conv\", k=5, s=2, t_1=2, z_1=16, routing=1),\n","            CapsuleLayer(2, 16, \"conv\", k=5, s=1, t_1=4, z_1=16, routing=3),\n","        )\n","        self.step_2 = nn.Sequential(  # 1/4\n","            CapsuleLayer(4, 16, \"conv\", k=5, s=2, t_1=4, z_1=32, routing=3),\n","            CapsuleLayer(4, 32, \"conv\", k=5, s=1, t_1=8, z_1=32, routing=3)\n","        )\n","        self.step_3 = nn.Sequential(  # 1/8\n","            CapsuleLayer(8, 32, \"conv\", k=5, s=2, t_1=8, z_1=64, routing=3),\n","            CapsuleLayer(8, 64, \"conv\", k=5, s=1, t_1=8, z_1=32, routing=3)\n","        )\n","        self.step_4 = CapsuleLayer(8, 32, \"deconv\", k=5, s=2, t_1=8, z_1=32, routing=3)\n","\n","        self.step_5 = CapsuleLayer(16, 32, \"conv\", k=5, s=1, t_1=4, z_1=32, routing=3)\n","\n","        self.step_6 = CapsuleLayer(4, 32, \"deconv\", k=5, s=2, t_1=4, z_1=16, routing=3)\n","        self.step_7 = CapsuleLayer(8, 16, \"conv\", k=5, s=1, t_1=4, z_1=16, routing=3)\n","        self.step_8 = CapsuleLayer(4, 16, \"deconv\", k=5, s=2, t_1=2, z_1=16, routing=3)\n","        self.step_10 = CapsuleLayer(3, 16, \"conv\", k=5, s=1, t_1=5, z_1=n_classes, routing=3)\n","        self.conv_2 = nn.Sequential(\n","            conv_function[index](16, n_classes, 5, padding=2,bias=False),\n","        )\n","    def forward(self, x):\n","        x = self.conv_1(x)\n","        x.unsqueeze_(1)\n","        skip_1 = x\n","        x = self.step_1(x)\n","        skip_2 = x \n","        x = self.step_2(x)\n","        skip_3 = x \n","        x = self.step_3(x)  \n","        x = self.step_4(x) \n","        x = torch.cat((x, skip_3), 1)  \n","\n","        x = self.step_5(x)  \n","\n","        x = self.step_6(x)\n","\n","        x = torch.cat((x, skip_2), 1)  \n","        x = self.step_7(x)  \n","        x = self.step_8(x) \n","        x=torch.cat((x,skip_1),1)\n","        x=self.step_10(x)\n","        x.squeeze_(1)\n","        v_lens = self.compute_vector_length(x)\n","        v_lens=v_lens.squeeze(1)\n","        return v_lens\n","    def compute_vector_length(self, x):\n","        out = (x.pow(2)).sum(1, True)+1e-9\n","        out=out.sqrt()\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DOjiVcw2XU2I"},"outputs":[],"source":["models = [UNet,AttenUNet,UNetplusplus,SegCaps]  \n","class CustomDataset(Dataset):\n","    def __init__(self, x, y):\n","        self.x = x\n","        self.y = y\n","    def __len__(self):\n","        return len(self.x)\n","    def __getitem__(self, index):\n","        return self.x[index], self.y[index]\n","def train(x_train,y_train,n_classes,names,d,batch_size,num_epochs,n_channels,n,learning_rate):\n","    global time_list\n","    global emissions\n","    device = 'cuda'\n","    metrics = []\n","    torch.manual_seed(42)\n","    y_train = torch.from_numpy(y_train).long()\n","    x_train = torch.from_numpy(x_train).float()\n","    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2,shuffle=True)\n","    train_dataset = CustomDataset(x_train, y_train)\n","    val_dataset = CustomDataset(x_val, y_val) \n","\n","    y = y_train.view(-1).numpy()\n","    class_counts = np.bincount(y)\n","    num_classes = len(class_counts)\n","    total_samples = len(y)\n","    class_weights = []\n","    for count in class_counts:\n","        freq = count / total_samples\n","        weight = 1/freq\n","        class_weights.append(weight)\n","\n","    class_weights = [x/sum(class_weights) for x in class_weights]\n","    class_weights = torch.FloatTensor(class_weights)\n","    class_weights = class_weights.to(device)\n","    \n","    criterion = nn.CrossEntropyLoss(weight=class_weights)\n","    print(\"y_train:\",y.shape,\"num_classes\",num_classes,\"class_weights:\",class_weights)\n","    q = 0\n","    b = batch_size\n","    temp = -1\n","    batch = []\n","    while q < len(names):                      \n","        try:\n","            if temp !=q:\n","                print(names[q]+d) \n","            train_losses = []\n","            train_accs = []\n","            val_losses = []\n","            val_accs = []\n","            tracker = EmissionsTracker(save_to_file=True, output_file='my_emissions.csv', log_level=\"ERROR\")\n","            tracker.start()\n","            t1 = time.time()\n","            model = models[n](n_channels, n_classes, bilinear=False,index=q)\n","            model.to(device)\n","            best_acc = 0.0\n","            train_dataloader = DataLoader(train_dataset, b, shuffle=True)\n","            val_dataloader = DataLoader(val_dataset, b, shuffle=True)\n","            l_t = len(train_dataloader)\n","            l_v = len(val_dataloader)\n","            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","            for epoch in range(num_epochs):\n","                running_loss = 0.0\n","                running_acc = 0.0\n","                t = 0\n","                v = 0\n","                model.train()\n","                for i, (inputs, labels) in enumerate(train_dataloader):\n","                    inputs = inputs.permute(0, 3, 1, 2)\n","                    inputs = inputs.to(device)\n","                    labels = labels.to(device)\n","                    optimizer.zero_grad()\n","                    outputs = model(inputs)\n","                    outputs = torch.exp(outputs)\n","                    loss = criterion(outputs, labels)\n","                    acc = (outputs.argmax(dim=1) == labels).float().mean()\n","                    loss.backward()\n","                    optimizer.step()\n","                    running_loss += loss.item()\n","                    running_acc += acc.item()\n","                    t+=1\n","                    print(f'\\rEpoch {epoch+1}: Train Progress: {int((t/l_t)*100)}%',end=\"\")\n","                train_losses.append(running_loss / len(train_dataloader))\n","                train_accs.append(running_acc / len(train_dataloader))\n","                val_loss = 0.0\n","                val_acc = 0.0\n","                model.eval()\n","                with torch.no_grad():\n","                    for i ,(inputs, labels) in enumerate(val_dataloader):\n","                        inputs = inputs.permute(0, 3, 1, 2)\n","                        inputs = inputs.to(device)\n","                        labels = labels.to(device)\n","                        outputs = model(inputs)\n","                        outputs = torch.exp(outputs)\n","                        loss = criterion(outputs, labels)\n","                        acc = (outputs.argmax(dim=1) == labels).float().mean()\n","                        val_loss += loss.item()\n","                        val_acc += acc.item()\n","                        v+=1\n","                        print(f'\\rEpoch {epoch+1}: Train Progress: {int((t/l_t)*100)}% Validation Progress: {int((v/l_v)*100)}%  ',end=\"\")\n","                val_losses.append(val_loss / len(val_dataloader))\n","                val_accs.append(val_acc / len(val_dataloader))\n","                scheduler.step(val_loss)\n","                print(f'Epoch {epoch+1}: Training Loss: {running_loss / len(train_dataloader):.4f}, Training Accuracy: {running_acc / len(train_dataloader):.4f}, Validation Loss: {val_loss / len(val_dataloader):.4f}, Validation Accuracy: {val_acc / len(val_dataloader):.4f}, batch_size: {b} ')\n","                if val_acc > best_acc:\n","                    best_acc = val_acc\n","                    torch.save(model.state_dict(),f'model/{names[q]}{d}.pth')                         \n","            t2 = time.time()\n","            tracker.stop()\n","            df = pd.read_csv('my_emissions.csv')\n","            df = df['emissions']\n","            total_emissions = df.sum()\n","            emissions.append(total_emissions)\n","            os.remove('my_emissions.csv')\n","            metrics.append({'train_losses': train_losses, 'train_accs': train_accs, 'val_losses': val_losses, 'val_accs': val_accs}) \n","            time_list.append((t2 - t1) / 60.0)\n","            batch.append(b)\n","            b = batch_size\n","            q+=1\n","        except Exception as e:\n","            if temp != q:\n","                print(e,\"for batch_size:\",batch_size)\n","                temp = q\n","            if b > 1:\n","                b -=1\n","            else:\n","                print(\"batch_size can't be reduced further, increase your gpu size\")\n","                return\n","    f, axarr = plt.subplots(len(names), 1, figsize=(10, 4*len(names))) \n","    epoch = range(1, num_epochs +1)\n","    for q in range(len(names)):\n","        axarr[q].plot(epoch, metrics[q]['train_losses'], marker='o', linestyle='-', color='blue', label=\"Training Loss\")\n","        axarr[q].plot(epoch, metrics[q]['val_losses'], marker='o', linestyle='-', color='red', label=\"Validation Loss\")\n","        axarr[q].plot(epoch, metrics[q]['train_accs'], marker='o', linestyle='-', color='green', label=\"Training Accuracy\")\n","        axarr[q].plot(epoch, metrics[q]['val_accs'], marker='o', linestyle='-', color='orange', label=\"Validation Accuracy\")\n","        axarr[q].set_ylim(0, 3)\n","        num_ticks = 25 \n","        axarr[q].set_yticks(np.linspace(0, 3, num_ticks))\n","        axarr[q].set_xlabel(\"Epochs\")\n","        axarr[q].set_ylabel(\"Metrics\")\n","        axarr[q].set_title(f\"{names[q]+d} (batch_size:{batch[q]},num_epochs:{num_epochs},learning_rate:{learning_rate})\")\n","        axarr[q].legend()\n","    plt.tight_layout()\n","    plt.savefig(\"output/train_models_\"+names[0]+d+\".png\",bbox_inches='tight')\n","    plt.close()           \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIcmvAB8ZD0M"},"outputs":[],"source":["def evaluate(x_test,y_test,names,d,batch_size,n_channels,n_classes,n):\n","    rows_table = []\n","    device = 'cuda'\n","    x_test = x_test.transpose(0, 3, 1, 2)\n","    x_test = torch.from_numpy(x_test).float()\n","    y_test = torch.from_numpy(y_test).long()\n","    test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n","    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","    l = len(test_loader)\n","    x_test.to(device)\n","    y_test.to(device)    \n","    for q in range(len(names)):\n","        model = models[n](n_channels, n_classes, bilinear=False,index=q)\n","        model.load_state_dict(torch.load(f'model/{names[q]}{d}.pth'))\n","        model.to(device)\n","        model.eval()\n","        outputs_list = []\n","        preds_list = []\n","        x = 0\n","        flops = 0\n","        with torch.no_grad():\n","            for x_batch, y_batch in test_loader:\n","                x_batch = x_batch.to(device)\n","                y_batch = y_batch.to(device)\n","                out_batch = model(x_batch)\n","                pred_batch = out_batch.argmax(dim=1)\n","                outputs_list.append(out_batch)\n","                preds_list.append(pred_batch)\n","                x+=1\n","                print(f'\\r{names[q]+d} Progress: {int((x/l)*100)}%',end=\"\")\n","        print()\n","        flops, _ = get_model_complexity_info(model, (3, 256, 256), as_strings=True, print_per_layer_stat=False)\n","        outputs = torch.cat(outputs_list, dim=0)\n","        preds = torch.cat(preds_list, dim=0)\n","        y_test_flat = y_test.flatten()\n","        preds_flat = preds.flatten().cpu().numpy()\n","        accuracy = accuracy_score(y_test_flat, preds_flat)\n","        kappa = cohen_kappa_score(y_test_flat, preds_flat)\n","        iou_score = jaccard_score(y_test_flat, preds_flat, average='macro')\n","        prec_score = precision_score(y_test_flat, preds_flat, average='macro')\n","        rec_score = recall_score(y_test_flat, preds_flat, average='macro')\n","        f1 = f1_score(y_test_flat, preds_flat, average='macro')\n","        cr = classification_report(y_test_flat, preds_flat)\n","        total_params = 0\n","        for param in model.parameters():\n","            num_params = param.numel()\n","            total_params += num_params\n","        rows_table.append(\n","        [names[q],\n","        f'{float(accuracy):.5f}' if isinstance(accuracy, (int, float)) else accuracy,\n","        f'{float(iou_score):.5f}' if isinstance(iou_score, (int, float)) else iou_score,\n","        f'{float(prec_score):.5f}' if isinstance(prec_score, (int, float)) else prec_score,\n","        f'{float(rec_score):.5f}' if isinstance(rec_score, (int, float)) else rec_score,\n","        f'{float(f1):.5f}' if isinstance(f1, (int, float)) else f1,\n","        f'{float(kappa):.5f}' if isinstance(kappa, (int, float)) else kappa,\n","        f'{float(total_params):.5f}' if isinstance(total_params, (int, float)) else total_params,\n","        f'{float(flops):.5f}' if isinstance(flops, (int, float)) else flops,\n","        cr,\n","        f'{float(emissions[q]):.2e}',\n","        f'{float(time_list[q]):.5f}'])\n","    print(cr)\n","    headers = [\"Model\", \"Accuracy\", \"IoU\", \"Precision\", \"Recall\", \"F1 Score\", \"Kappa\", \"Parameters\",\"Flops\",\"Classification Report\",\"Carbon Emmission(kgCO2eq)\",\"Train time(min)\"]\n","    fig, ax = plt.subplots()\n","    ax.axis('off')\n","    table = ax.table(cellText=rows_table, colLabels=headers, loc='center', cellLoc='center')\n","    table.auto_set_font_size(False)\n","    table.set_fontsize(10)\n","    table.auto_set_column_width(col=[9])\n","    table.auto_set_column_width(col=[10])\n","    table.auto_set_column_width(col=[11])\n","    table.scale(3*1, 6*2)\n","    for i, header in enumerate(headers):\n","        table[0, i].get_text().set_fontweight('bold')\n","    plt.savefig('output/table_'+names[0]+d+'.png',bbox_inches='tight')\n","    plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aWC2zs64ZeW5"},"outputs":[],"source":["def hex_to_rgb(hex_code):\n","  rgb=np.array(tuple(int(hex_code[i:i+2],16) for i in (0,2,4)))\n","  return rgb\n","corn = hex_to_rgb(\"ffd300\")\n","soyabean=  hex_to_rgb(\"267000\")\n","cotton = hex_to_rgb(\"ff2626\")\n","spring_wheat = hex_to_rgb(\"d8b56b\")\n","outside_usa=np.array([0,0,0])\n","def get_mask1(arr):\n","    map_dict = {'corn': corn, 'soyabean': soyabean, 'cotton': cotton, 'spring_wheat':spring_wheat,'outside_usa':outside_usa}\n","    mask = np.zeros((arr.shape[0], arr.shape[1], 3))\n","    mask[arr == 0, :] = map_dict['corn']\n","    mask[arr == 1, :] = map_dict['soyabean']\n","    mask[arr == 2, :] = map_dict['cotton']\n","    mask[arr == 3, :] = map_dict['spring_wheat']\n","    mask[arr == 4, :] = map_dict['outside_usa']\n","    return mask\n","def get_mask2(arr):\n","    map_dict = {'b': np.array([[[0, 0, 255]]]), 'g': np.array([[[0, 255, 0]]]), 'r': np.array([[[255, 0, 0]]])}\n","    mask = np.zeros((arr.shape[0], arr.shape[1], 3))\n","    mask[arr == 1, :] = map_dict['b']\n","    mask[arr == 2, :] = map_dict['g']\n","    mask[arr == 3, :] = map_dict['r']\n","    return mask\n","get_mask_func = [get_mask1,get_mask2,get_mask2]\n","def plot(x_test,y_test,names,d,n_channels, n_classes,n):\n","    get_mask = get_mask_func[int(d)-1]\n","    device = 'cuda'\n","    h= x_test.shape[2]\n","    x_test_tensor = torch.from_numpy(x_test).permute(0, 3, 1, 2).float()\n","    x_test_tensor = x_test_tensor.to(device)\n","    f, axarr = plt.subplots(6, len(names)+2, figsize=(3 * (len(names)+2), 3 * 6))\n","    cnt=0\n","    for i in [18,21,25,15,99,51]:\n","      axarr[0,0].set_title('NDVI', fontweight='bold', fontsize=16)\n","      axarr[0,1].set_title('GT', fontweight='bold', fontsize=16)\n","      axarr[cnt,0].imshow(x_test[i])\n","      axarr[cnt,1].imshow(get_mask(y_test[i].reshape((h, h))))\n","      cnt=cnt+1\n","    for q in range(len(names)):\n","        cnt=0\n","        for i in [18,21,25,15,99,51]:\n","            model = models[n](n_channels, n_classes, bilinear=False,index=q)\n","            model.load_state_dict(torch.load(f'model/{names[q]}{d}.pth'))\n","            model.to(device)\n","            model.eval()\n","            test_img = model.forward(x_test_tensor[i:i + 1])\n","            test_img = torch.argmax(test_img, dim=1)\n","            test_img = test_img.cpu().numpy().squeeze()\n","            test_img = get_mask(test_img.reshape((h, h)))\n","            test_img = np.clip(test_img, 0, h-1)\n","            axarr[0,q+2].set_title(names[q], fontweight='bold', fontsize=16)\n","            axarr[cnt, q+2].imshow(test_img / (h-1))\n","            cnt+=1\n","    plt.savefig('output/plot_'+names[0]+d+'.png',bbox_inches='tight')\n","    plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#run\n","n = int(input(\"Select architecture number: 1-UNet, 2-Attention-UNet, 3-UNet++, 4-SegCaps:  \"))\n","d = int(input(\"Select dataset number: 1, 2, 3:  \"))\n","names = {}\n","time_list = []\n","emissions = [] \n","names[1] = ['UNet', 'UNet_SSC', 'UNet_GDC', 'UNet_DC', 'UNet_ADC', 'UNet_orgAC', 'UNet_AC','UNet_GD_AC', 'UNet_D_AC', 'UNet_AD_AC']\n","names[2] = ['AttenUnet', 'AttenUnet_SSC', 'AttenUnet_GDC', 'AttenUnet_DC','AttenUnet_ADC','AttenUnet_orgAC', 'AttenUnet_AC',  'AttenUnet_GD_AC', 'AttenUnet_D_AC','AttenUnet_AD_AC']\n","names[3] = ['UNet++', 'UNet++_SSC', 'UNet++_GDC', 'UNet++_DC','UNet++_ADC', 'UNet++_orgAC', 'UNet++_AC','UNet++_GD_AC', 'UNet++_D_AC','UNet++_AD_AC']\n","names[4] = ['SegCaps', 'SegCaps_SSC', 'SegCaps_GDC', 'SegCaps_DC', 'SegCaps_ADC', 'SegCaps_orgAC', 'SegCaps_AC','SegCaps_GD_AC', 'SegCaps_D_AC', 'SegCaps_AD_AC']\n","d = str(d)\n","if d == '1':\n","    y_train = np.load('datasets/dataset'+d+'/y_train.npz')['arr_0']\n","    x_train = np.load('datasets/dataset'+d+'/x_train.npz')['arr_0']\n","    x_test = np.load('datasets/dataset'+d+'/x_test.npz')['arr_0']\n","    y_test = np.load('datasets/dataset'+d+'/y_test.npz')['arr_0']\n","    n_classes = len(np.unique(y_train))\n","else:\n","    y_train = np.load('datasets/dataset'+d+'/y_train.npy')\n","    x_train = np.load('datasets/dataset'+d+'/x_train.npy')\n","    x_test = np.load('datasets/dataset'+d+'/x_test.npy')\n","    y_test = np.load('datasets/dataset'+d+'/y_test.npy')\n","    n_classes = len(np.unique(y_train))\n","    y_train = np.squeeze(y_train, axis=-1)\n","    y_test = np.squeeze(y_test,axis=-1)\n","n_channels = x_train.shape[3]\n","batch_size = int(input(\"Input batch size number:  \"))\n","num_epochs = int(input(\"Input number of epochs:  \"))\n","learning_rate = float(input(\"Input learning rate: \"))      \n","print(\"x_train\",x_train.shape,\"y_train:\",y_train.shape,\"x_test\",x_test.shape,y_test.shape,\"num_classes:\",n_classes)\n","print(\"Training...\")\n","train(x_train,y_train,n_classes,names[n],d,batch_size,num_epochs,n_channels,n-1,learning_rate)\n","print(\"Evaluating...\")\n","evaluate(x_test,y_test,names[n],d,1,n_channels,n_classes,n-1)\n","print(\"Plotting...\")\n","plot(x_test,y_test,names[n],d,n_channels, n_classes,n-1)\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
